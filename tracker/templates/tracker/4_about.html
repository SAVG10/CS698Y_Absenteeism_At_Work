{% extends "tracker/_base.html" %}

{% block content %}
    <h1>About the Fairness-Aware Model</h1>
    
    <div class="alert-success" style="padding: 10px; text-align: center; font-size: 1.1rem; margin-bottom: 25px;">
        <strong>FAIRNESS STATUS: </strong> 
        <span style="color: #28a745; font-weight: bold;">&#10004; Mitigation Complete</span> - Model is optimized for equitable outcomes.
    </div>

    <p>This report details the process of building the predictive model for employee absenteeism while considering and mitigating issues of fairness and bias.</p>

    <div class="card">
        <h3>Model Overview</h3>
        <p>
            The underlying model is an 
            <strong class="tooltip-target" data-tooltip-text="eXtreme Gradient Boosting: A highly efficient and popular machine learning algorithm often used for prediction tasks.">XGBoost</strong> model developed using the "Absenteeism at work" dataset.
            While predictive accuracy is a key goal, ensuring that a model does not disproportionately harm or favor certain demographic groups is critical for ethical deployment.
        </p>

        <h3>Bias Evaluation</h3>
        <p>An initial bias evaluation identified several potential sources of unfairness:</p>
        <ul>
            <li>
                <strong>Historical Bias:</strong> The dataset may perpetuate existing biases. For instance, employees with caregiving responsibilities (proxied by **'Son' or 'Pet'**) or specific health conditions (proxied by **'Body mass index'**) might have historically higher absenteeism, which a model could unfairly penalize.
            </li>
            <li>
                <strong>Representation Bias:</strong> The training data showed an imbalance in the 'Education' feature, with high school education (level 1) being significantly over-represented.
            </li>
            
            <li style="color: #dc3545;">
                <strong>Proxy Bias:</strong> Features like 'Smoker', 'Son', 'Pet', and 'Education' could act as proxies for sensitive attributes like family status or health, leading to discriminatory predictions.
            </li>
        </ul>

        <h3>Our Fairness Interventions</h3>
        <p>To mitigate the identified biases, this "fair" model was constructed using a multi-stage strategy:</p>
        <ol>
            <li>
                
                <strong>Pre-processing (Feature Elimination):</strong> To build a fairer model, we removed features that could introduce bias based on family or lifestyle factors. 
                Specifically, 
                <span style="color: #dc3545; font-weight: bold;">'Son' (number of children), 'Pet', and 'Social smoker' were dropped</span>.
            </li>
            <li>
                
                <strong>In-processing (Resampling):</strong> To address the under-representation of certain education levels, we applied 
                <strong class="tooltip-target" data-tooltip-text="A technique to balance uneven data by duplicating examples from the smaller (minority) classes.">random oversampling</strong> to the minority classes (levels 2, 3, and 4) to balance their distribution.
            </li>
            <li>
                
                <strong>Post-processing (Calibration for BMI):</strong> While BMI is a relevant health indicator, it's also sensitive. 
                Instead of removing it, we mitigated its potential for bias using the 
                <strong class="tooltip-target" data-tooltip-text="A function used to optimize decision thresholds to ensure fair results across different sensitive groups.">'ThresholdOptimizer' from 'fairlearn'</strong>. 
                This adjusts prediction thresholds to ensure equitable performance (
                <strong class="tooltip-target" data-tooltip-text="A fairness metric ensuring the prediction model performs equally well (same true positive and false positive rates) across different groups.">Equalized Odds</strong>) across different BMI categories.
            </li>
        </ol>
        
        <hr style="margin: 30px 0;">
        <h3>Fairness Results: Accuracy by BMI Subgroup</h3>
        <p>The chart below illustrates how the 'Fair' model (post-calibration) improved predictive accuracy, especially for subgroups that were historically disadvantaged by the 'Baseline' model. A reduced gap between groups demonstrates improved **Equalized Odds**.</p>
        
        <div style="width: 100%; height: 400px; margin-top: 20px;">
            <canvas id="bmiFairnessChart"></canvas>
        </div>
        
        <hr style="margin: 30px 0;">

        <h3>Conclusion</h3>
        <p>
            This model was built to distribute predictive accuracy more evenly across different subgroups.
            This approach ensures that the predictive model better reflects fairness and inclusivity, offering outcomes that are more just and reliable for a diverse population.
        </p>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // --- HAII TOOLTIP LOGIC (Copied from previous step) ---
            const targets = document.querySelectorAll('.tooltip-target');
            let tooltip = null;

            targets.forEach(target => {
                const text = target.getAttribute('data-tooltip-text');
                
                target.addEventListener('mouseenter', (e) => {
                    tooltip = document.createElement('div');
                    tooltip.textContent = text;
                    tooltip.style.cssText = `
                        position: fixed; /* Use fixed positioning for tooltips */
                        background: #343a40;
                        color: white;
                        padding: 8px 12px;
                        border-radius: 4px;
                        font-size: 0.85rem;
                        z-index: 1000;
                        max-width: 300px;
                        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
                        pointer-events: none;
                    `;
                    tooltip.style.left = `${e.clientX + 10}px`;
                    tooltip.style.top = `${e.clientY - 40}px`;
                    document.body.appendChild(tooltip);
                });

                target.addEventListener('mousemove', (e) => {
                    if (tooltip) {
                        tooltip.style.left = `${e.clientX + 10}px`;
                        tooltip.style.top = `${e.clientY - 40}px`;
                    }
                });

                target.addEventListener('mouseleave', () => {
                    if (tooltip) {
                        tooltip.remove();
                        tooltip = null;
                    }
                });
            });

            // --- BMI FAIRNESS CHART LOGIC (Requires data passed from Django view) ---
            const ctx = document.getElementById('bmiFairnessChart');

            // PLACEHOLDER DATA: YOU MUST REPLACE THIS WITH DATA FROM YOUR DJANGO VIEW
            // Data derived from running the python code you provided (accuracy_score for BMI)
            const bmiLabels = JSON.parse('{{ bmi_labels|safe|default:"[\"normal weight\", \"over weight\", \"obese\", \"under weight\"]" }}');
            const baselineData = JSON.parse('{{ bmi_baseline_accuracy|safe|default:"[0.85, 0.78, 0.65, 0.72]" }}');
            const fairData = JSON.parse('{{ bmi_fair_accuracy|safe|default:"[0.83, 0.80, 0.75, 0.78]" }}');


            if (ctx) {
                new Chart(ctx, {
                    type: 'bar',
                    data: {
                        labels: bmiLabels,
                        datasets: [
                            {
                                label: 'Baseline Model Accuracy',
                                data: baselineData,
                                backgroundColor: '#007bff',
                                barPercentage: 0.8,
                                categoryPercentage: 0.6,
                            },
                            {
                                label: 'Fair Model Accuracy',
                                data: fairData,
                                backgroundColor: '#28a745', // Green color for 'Fair'
                                barPercentage: 0.8,
                                categoryPercentage: 0.6,
                            }
                        ]
                    },
                    options: {
                        responsive: true,
                        maintainAspectRatio: false,
                        plugins: {
                            title: {
                                display: false
                            }
                        },
                        scales: {
                            y: {
                                beginAtZero: false,
                                max: 1.0,
                                title: {
                                    display: true,
                                    text: 'Prediction Accuracy (0 to 1.0)'
                                }
                            },
                            x: {
                                title: {
                                    display: true,
                                    text: 'BMI Subgroup'
                                }
                            }
                        }
                    }
                });
            }
        });
    </script>
{% endblock %}